{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":9261924,"sourceType":"datasetVersion","datasetId":5604290}],"dockerImageVersionId":30761,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# %% [markdown]\n# # Machine Learning-based Web Application Firewall\n\n# %% [markdown]\n# ## Imports\n\n# %%\nimport pandas as pd\nimport numpy as np\nfrom sklearn.preprocessing import StandardScaler\nfrom pycaret.classification import *\nfrom sklearn.cluster import KMeans\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom elasticsearch import Elasticsearch\nimport time\nfrom urllib.parse import urlparse\nimport requests\nfrom http.server import HTTPServer, BaseHTTPRequestHandler\nfrom socketserver import ThreadingMixIn\nimport threading\nimport joblib\nimport streamlit as st\n\n# %% [markdown]\n# ## Data Loading and Preprocessing\n\n# %%\nclass DataLoader:\n    def __init__(self, file_path):\n        self.file_path = file_path\n\n    def load_and_preprocess_data(self):\n        df = pd.read_csv(self.file_path)\n        X = df.drop(['label', 'timestamp'], axis=1)\n        y = df['label']\n        scaler = StandardScaler()\n        X_scaled = scaler.fit_transform(X)\n        df_preprocessed = pd.DataFrame(X_scaled, columns=X.columns)\n        df_preprocessed['label'] = y\n        df_preprocessed['timestamp'] = df['timestamp']\n        return df_preprocessed\n\n# %% [markdown]\n# ## Model Training\n\n# %%\nclass ModelTrainer:\n    def __init__(self):\n        self.model = None\n\n    def train_model(self, df):\n        clf = setup(data=df, target='label', session_id=123, normalize=True, transformation=True, \n                    ignore_features=['timestamp'], silent=True, use_gpu=True)\n        best_model = compare_models(sort='AUC')\n        tuned_model = tune_model(best_model)\n        self.model = finalize_model(tuned_model)\n        return self.model\n\n    def save_model(self, path):\n        save_model(self.model, path)\n\n    def load_model(self, path):\n        self.model = load_model(path)\n\n# %% [markdown]\n# ## Clustering\n\n# %%\nclass Clusterer:\n    def __init__(self, n_clusters=5):\n        self.n_clusters = n_clusters\n        self.kmeans = None\n\n    def perform_clustering(self, df):\n        features = df.drop(['label', 'timestamp'], axis=1)\n        self.kmeans = KMeans(n_clusters=self.n_clusters, random_state=42)\n        df['cluster'] = self.kmeans.fit_predict(features)\n        return df\n\n    def save_model(self, path):\n        joblib.dump(self.kmeans, path)\n\n    def load_model(self, path):\n        self.kmeans = joblib.load(path)\n\n# %% [markdown]\n# ## Visualization\n\n# %%\nclass Visualizer:\n    @staticmethod\n    def visualize_anomalies_clusters(df):\n        fig, ax = plt.subplots(figsize=(12, 8))\n        scatter = ax.scatter(df['feature1'], df['feature2'], c=df['cluster'], cmap='viridis', alpha=0.7)\n        ax.scatter(df[df['label'] == 1]['feature1'], df[df['label'] == 1]['feature2'], color='red', marker='x', s=100, label='Anomaly')\n        ax.set_title('Anomalies in Clusters')\n        ax.set_xlabel('Feature 1')\n        ax.set_ylabel('Feature 2')\n        ax.legend()\n        plt.colorbar(scatter, label='Cluster')\n        return fig\n\n# %% [markdown]\n# ## Elasticsearch Logger\n\n# %%\nclass ElasticsearchLogger:\n    def __init__(self, es_host='localhost', es_port=9200, index_name='waf_logs'):\n        self.es = Elasticsearch([{'host': es_host, 'port': es_port}])\n        self.index_name = index_name\n\n    def log_request(self, request_data, is_intrusion):\n        doc = {\n            'timestamp': time.time(),\n            'method': request_data['method'],\n            'path': request_data['path'],\n            'is_intrusion': is_intrusion\n        }\n        self.es.index(index=self.index_name, body=doc)\n\n# %% [markdown]\n# ## DDoS Protection\n\n# %%\nclass DDoSProtection:\n    def __init__(self, time_window=60, request_limit=100):\n        self.time_window = time_window\n        self.request_limit = request_limit\n        self.request_log = {}\n\n    def is_ddos_attack(self, client_ip):\n        current_time = time.time()\n        if client_ip not in self.request_log:\n            self.request_log[client_ip] = []\n        self.request_log[client_ip] = [t for t in self.request_log[client_ip] if current_time - t < self.time_window]\n        self.request_log[client_ip].append(current_time)\n        return len(self.request_log[client_ip]) > self.request_limit\n\n# %% [markdown]\n# ## URL Filtering\n\n# %%\ndef is_malicious_url(url):\n    malicious_domains = ['malware.com', 'phishing.com', 'spam.com']\n    parsed_url = urlparse(url)\n    return parsed_url.netloc in malicious_domains\n\n# %% [markdown]\n# ## Intrusion Detection\n\n# %%\ndef detect_intrusion(request_data, model):\n    features = pd.DataFrame([{\n        'method': request_data['method'],\n        'path_length': len(request_data['path']),\n        'header_count': len(request_data['headers']),\n        'body_length': len(request_data['body'])\n    }])\n    prediction = predict_model(model, data=features)\n    return prediction['prediction_label'][0] == 1\n\n# %% [markdown]\n# ## Proxy Server\n\n# %%\nclass MLProxyHandler(BaseHTTPRequestHandler):\n    def __init__(self, *args, **kwargs):\n        self.model = kwargs.pop('model')\n        self.es_logger = kwargs.pop('es_logger')\n        self.ddos_protection = kwargs.pop('ddos_protection')\n        super().__init__(*args, **kwargs)\n\n    def do_METHOD(self):\n        client_ip = self.client_address[0]\n        if self.ddos_protection.is_ddos_attack(client_ip):\n            self.send_error(429, \"Too Many Requests\")\n            return\n\n        method = self.command\n        path = self.path\n        headers = self.headers\n        body = self.rfile.read(int(self.headers.get('Content-Length', 0)))\n\n        request_data = {\n            'method': method,\n            'path': path,\n            'headers': dict(headers),\n            'body': body.decode('utf-8')\n        }\n\n        is_intrusion = detect_intrusion(request_data, self.model)\n        self.es_logger.log_request(request_data, is_intrusion)\n\n        if is_intrusion or is_malicious_url(path):\n            self.send_error(403, \"Potential intrusion detected\")\n        else:\n            try:\n                response = requests.request(\n                    method=method,\n                    url=f\"http://localhost:8080{path}\",  # Replace with your target server\n                    headers=headers,\n                    data=body,\n                    timeout=5\n                )\n                self.send_response(response.status_code)\n                for header, value in response.headers.items():\n                    self.send_header(header, value)\n                self.end_headers()\n                self.wfile.write(response.content)\n            except Exception as e:\n                self.send_error(500, str(e))\n\n    do_GET = do_POST = do_PUT = do_DELETE = do_METHOD\n\nclass ThreadedHTTPServer(ThreadingMixIn, HTTPServer):\n    pass\n\n# %% [markdown]\n# ## Main Function\n\n# %%\ndef main():\n    print(\"Machine Learning-based Web Application Firewall\")\n\n    data_loader = DataLoader(\"/kaggle/input/demo123\")  # Replace with your dataset path\n    df = data_loader.load_and_preprocess_data()\n\n    model_trainer = ModelTrainer()\n    model = model_trainer.train_model(df)\n    model_trainer.save_model(\"waf_model.pkl\")\n\n    clusterer = Clusterer()\n    df_clustered = clusterer.perform_clustering(df)\n    clusterer.save_model(\"kmeans_model.pkl\")\n\n    print(\"Anomalies in Clusters\")\n    fig = Visualizer.visualize_anomalies_clusters(df_clustered)\n    plt.show()\n\n    es_logger = ElasticsearchLogger()\n    ddos_protection = DDoSProtection()\n\n    print(\"Proxy Server\")\n    handler = lambda *args, **kwargs: MLProxyHandler(*args, model=model, es_logger=es_logger, ddos_protection=ddos_protection, **kwargs)\n    server = ThreadedHTTPServer(('localhost', 8000), handler)\n    print(\"Proxy server is running on http://localhost:8000\")\n    server.serve_forever()\n\n# %% [markdown]\n# ## Run the Application\n\n# %%\nif __name__ == \"__main__\":\n    main()","metadata":{"execution":{"iopub.status.busy":"2024-08-27T22:22:17.970124Z","iopub.execute_input":"2024-08-27T22:22:17.970683Z","iopub.status.idle":"2024-08-27T22:22:20.713711Z","shell.execute_reply.started":"2024-08-27T22:22:17.970632Z","shell.execute_reply":"2024-08-27T22:22:20.711756Z"},"trusted":true},"execution_count":1,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","Cell \u001b[0;32mIn[1], line 11\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m StandardScaler\n\u001b[0;32m---> 11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpycaret\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mclassification\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcluster\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m KMeans\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pycaret'"],"ename":"ModuleNotFoundError","evalue":"No module named 'pycaret'","output_type":"error"}]},{"cell_type":"code","source":"pip install pycaret\n","metadata":{"execution":{"iopub.status.busy":"2024-08-27T22:23:08.439471Z","iopub.execute_input":"2024-08-27T22:23:08.439934Z","iopub.status.idle":"2024-08-27T22:25:38.796396Z","shell.execute_reply.started":"2024-08-27T22:23:08.439889Z","shell.execute_reply":"2024-08-27T22:25:38.795004Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"\u001b[33mWARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x7cc57738f520>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution')': /simple/pycaret/\u001b[0m\u001b[33m\n\u001b[0m\u001b[33mWARNING: Retrying (Retry(total=3, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x7cc57738f820>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution')': /simple/pycaret/\u001b[0m\u001b[33m\n\u001b[0m\u001b[33mWARNING: Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x7cc57738fac0>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution')': /simple/pycaret/\u001b[0m\u001b[33m\n\u001b[0m\u001b[33mWARNING: Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x7cc57738fc70>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution')': /simple/pycaret/\u001b[0m\u001b[33m\n\u001b[0m\u001b[33mWARNING: Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x7cc57738fe20>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution')': /simple/pycaret/\u001b[0m\u001b[33m\n\u001b[0m\u001b[31mERROR: Could not find a version that satisfies the requirement pycaret (from versions: none)\u001b[0m\u001b[31m\n\u001b[0m\u001b[31mERROR: No matching distribution found for pycaret\u001b[0m\u001b[31m\n\u001b[0mNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}]}]}